{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiratkJaura/Final-Project-02/blob/main/Final_Project_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K-tsxoMe0Hs"
      },
      "source": [
        "#Final Project 02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7ebIz7Xe5Tk",
        "outputId": "3c07c467-7094-46f8-9f24-125d61efefa3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1942 images belonging to 3 classes.\n",
            "Found 431 images belonging to 3 classes.\n",
            "Class names: ['crack', 'missing-head', 'paint-off']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1471s\u001b[0m 23s/step - accuracy: 0.3863 - loss: 3.8583 - val_accuracy: 0.4231 - val_loss: 1.0226\n",
            "Epoch 2/15\n",
            "\u001b[1m 1/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:56\u001b[0m 21s/step - accuracy: 0.4062 - loss: 1.0033"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.4062 - loss: 1.0033 - val_accuracy: 0.3333 - val_loss: 0.9874\n",
            "Epoch 3/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1317s\u001b[0m 21s/step - accuracy: 0.5008 - loss: 0.9885 - val_accuracy: 0.5216 - val_loss: 0.8566\n",
            "Epoch 4/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.5938 - loss: 0.8709 - val_accuracy: 0.5333 - val_loss: 0.8755\n",
            "Epoch 5/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1272s\u001b[0m 21s/step - accuracy: 0.5986 - loss: 0.8519 - val_accuracy: 0.5625 - val_loss: 0.8237\n",
            "Epoch 6/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.6250 - loss: 0.7601 - val_accuracy: 0.6000 - val_loss: 0.6980\n",
            "Epoch 7/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 21s/step - accuracy: 0.5910 - loss: 0.8423 - val_accuracy: 0.6130 - val_loss: 0.7649\n",
            "Epoch 8/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.6875 - loss: 0.5788 - val_accuracy: 0.6000 - val_loss: 0.7152\n",
            "Epoch 9/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 21s/step - accuracy: 0.5967 - loss: 0.8257 - val_accuracy: 0.5865 - val_loss: 0.7668\n",
            "Epoch 10/15\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 918ms/step - accuracy: 0.7500 - loss: 0.5827 - val_accuracy: 0.4000 - val_loss: 1.2232\n",
            "Epoch 11/15\n",
            "\u001b[1m22/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m12:39\u001b[0m 20s/step - accuracy: 0.6313 - loss: 0.7668"
          ]
        }
      ],
      "source": [
        "# AER 850  Project 2\n",
        "# Author: Kirat Kaur\n",
        "# Student No: 501125524\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Data Processing\n",
        "\n",
        "image_size = (500, 500)\n",
        "batch_size = 32\n",
        "\n",
        "# Directories for training, validation, and testing data\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Project 02; AER 850/Data/train'\n",
        "val_dir = '/content/drive/MyDrive/Colab Notebooks/Project 02; AER 850/Data/valid'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/Project 02; AER 850/Data/test'\n",
        "\n",
        "# Image data generators with augmentation for training and simple scaling for validation/testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Creating generators\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
        "val_generator = val_datagen.flow_from_directory(val_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "# Retrieving class names based on directory structure\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# Step 2: Neural Network Architecture Design\n",
        "model = models.Sequential()\n",
        "\n",
        "# First Convolutional layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(500, 500, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second Convolutional layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Third Convolutional layer\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flattening and adding Dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))                    # Dropout to reduce overfitting\n",
        "model.add(layers.Dense(3, activation='softmax'))  # Output layer for 3 classes\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Model Training and Evaluation with Early Stopping\n",
        "\n",
        "# Training the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  ## early stopping\n",
        "\n",
        "history = model.fit(\n",
        "   train_generator,\n",
        "   steps_per_epoch=train_generator.samples // batch_size,\n",
        "   epochs=15,\n",
        "   validation_data=val_generator,\n",
        "   validation_steps=val_generator.samples // batch_size,\n",
        "   callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "\n",
        "# Plots for training & validation accuracy, and loss\n",
        "\n",
        "# Plotting accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plotting loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Model Testing\n",
        "\n",
        "# Function to preprocess test image\n",
        "def preprocess_test_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=image_size)\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    return np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predicting on a single test images for crack, missing-head, and paint-off\n",
        "\n",
        "# Crack single image test\n",
        "test_img_path = '/content/drive/MyDrive/Colab Notebooks/Project 02; AER 850/Data/test/crack/test_crack.jpg'\n",
        "test_img = preprocess_test_image(test_img_path)\n",
        "prediction = model.predict(test_img)\n",
        "\n",
        "# Missing-head single image test\n",
        "test_img_path = '/content/drive/MyDrive/Colab Notebooks/Project 02; AER 850/Data/test/missing-head/test_missinghead.jpg'\n",
        "test_img = preprocess_test_image(test_img_path)\n",
        "prediction = model.predict(test_img)\n",
        "\n",
        "# Paint-off single image test\n",
        "test_img_path = '/content/drive/MyDrive/Colab Notebooks/Project 02; AER 850/Data/test/paint-off/test_paintoff.jpg'\n",
        "test_img = preprocess_test_image(test_img_path)\n",
        "prediction = model.predict(test_img)\n",
        "\n",
        "# Finding the predicted class\n",
        "predicted_class = np.argmax(prediction)\n",
        "class_names = ['Crack', 'Missing Head', 'Paint Off']\n",
        "print(f\"The model predicts this image as: {class_names[predicted_class]}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HkQBkKSmTpQ-L6b6BfJW_e3cUc6Deb2j",
      "authorship_tag": "ABX9TyOZabKNcBh7UPHKfYRAxl/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}